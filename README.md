# üìä PR√ÅCTICA 3: IDENTIFICACI√ìN DE FRASES CLAVE Y RESUMEN AUTOM√ÅTICO DE TEXTO
## Tecnolog√≠as de Lenguaje Natural

**Autor:** Escamilla Lazcano Sa√∫l
**Grupo:** 5BV1
**Carrera:** Ingenier√≠a En Inteligencia Artificial

[![Python](https://img.shields.io/badge/Python-3.10-blue.svg)](https://www.python.org/)
[![spaCy](https://img.shields.io/badge/Librer√≠a-spaCy-blue.svg)](https://spacy.io/)
[![NLTK](https://img.shields.io/badge/Librer√≠a-NLTK-green.svg)](https://www.nltk.org/)
[![Transformers](https://img.shields.io/badge/Librer√≠a-Transformers-yellow.svg)](https://huggingface.co/sentence-transformers)
[![Scikit-Learn](https://img.shields.io/badge/Librer√≠a-Scikit--Learn-orange.svg)](https://scikit-learn.org/stable/)

## üöÄ Descripci√≥n General del Proyecto

Este proyecto es un an√°lisis comparativo exhaustivo de **seis algoritmos de resumen autom√°tico extractivo**, desarrollado en un Jupyter Notebook. El objetivo es procesar las cuatro primeras cartas del libro "Frankenstein", aplicar cada algoritmo para extraer las 12 oraciones m√°s representativas y, finalmente, realizar un an√°lisis cuantitativo y cualitativo para determinar el "mejor" algoritmo seg√∫n un balance de m√©tricas.

El proyecto demuestra cinco competencias clave:
1.  **Extracci√≥n de Texto:** Descarga y parseo del texto de "Frankenstein" desde *Project Gutenberg* usando expresiones regulares.
2.  **Normalizaci√≥n Justificada:** Implementaci√≥n de estrategias de pre-procesamiento personalizadas para cada algoritmo, justificando por qu√© un enfoque √∫nico no es adecuado.
3.  **Implementaci√≥n de Algoritmos:** Implementaci√≥n desde cero (o con bibliotecas clave) de seis m√©todos de resumen: TF-IDF, Frecuencia, RAKE, TextRank, BERT y LSA.
4.  **An√°lisis Cuantitativo:** Medici√≥n y visualizaci√≥n del tiempo de ejecuci√≥n, la escalabilidad y la variabilidad del rendimiento de cada m√©todo.
5.  **An√°lisis Cualitativo:** Evaluaci√≥n de la calidad del resumen midiendo la similitud (solapamiento) entre las selecciones de oraciones y creando una r√∫brica de evaluaci√≥n multidimensional.

---

## üìÇ 1. Corpus de Datos

* **Texto de entrada:** Las cuatro primeras cartas del libro "Frankenstein" (URL de Project Gutenberg: `pg84.txt`).
* **Par√°metro de resumen:** `n=12` oraciones para cada resumen.
* **M√≥dulos de procesamiento**: NLTK, `sklearn`, `sentence-transformers` (BERT), `networkx` (TextRank), y `rake-nltk`.

## üî° 2. Normalizaci√≥n de Texto (Punto 2)

Un requisito clave fue **justificar** por qu√© se normaliza el texto de manera diferente para cada algoritmo. Aplicar una normalizaci√≥n √∫nica y agresiva (como quitar toda la puntuaci√≥n) es beneficioso para algunos m√©todos, pero perjudicial para otros.

| Algoritmo | Justificaci√≥n de Normalizaci√≥n |
| :--- | :--- |
| **TF-IDF, Frecuencia, LSA, TextRank** | Se conserva la puntuaci√≥n b√°sica (`., !, ?`) para permitir que `sent_tokenize` de NLTK segmente las oraciones correctamente. El resto del ruido (s√≠mbolos, espacios extra) se elimina. LSA adem√°s requiere min√∫sculas (`.lower()`). |
| **RAKE** | Se conserva **casi toda** la puntuaci√≥n. RAKE (Rapid Automatic Keyword Extraction) la utiliza como delimitador para identificar frases clave, por lo que eliminarla romper√≠a el algoritmo. |
| **BERT** | **Normalizaci√≥n m√≠nima**. Se conserva la puntuaci√≥n, may√∫sculas y subt√≠tulos (`_..._`). BERT es un modelo contextual profundo que entiende el significado sem√°ntico del formato, por lo que eliminar esta informaci√≥n *empeorar√≠a* sus resultados. |

---

## ü§ñ 3. Implementaci√≥n de Algoritmos (Punto 3)

Se implementaron seis algoritmos extractivos. Todos seleccionan las 12 oraciones con mayor puntaje y las reordenan cronol√≥gicamente para mantener la coherencia.

| Algoritmo | Biblioteca/M√≥dulo | L√≥gica de Puntuaci√≥n (para una oraci√≥n) |
| :--- | :--- | :--- |
| **TF-IDF** | `TfidfVectorizer` (sklearn) | Suma de los puntajes TF-IDF de todas las palabras que contiene. Importante si tiene palabras raras en el contexto global. |
| **Frecuencia** | `CountVectorizer` / Manual | Promedio de la frecuencia normalizada de sus palabras (excluyendo *stopwords*). Importante si contiene palabras muy comunes. |
| **RAKE** | `rake-nltk` | Suma de los puntajes RAKE de las frases clave que aparecen en ella. Importante si contiene muchas frases clave relevantes. |
| **TextRank** | `networkx` / `TfidfVectorizer` | Aplicaci√≥n de PageRank sobre un grafo donde las oraciones son nodos y las aristas son su similitud (TF-IDF). Importante si es similar a otras oraciones importantes. |
| **BERT** | `SentenceTransformer` | Similitud coseno entre el vector de la oraci√≥n y el vector del documento completo. Importante si su *significado sem√°ntico* es central al tema general. |
| **LSA** | `TruncatedSVD` (sklearn) | Suma de la magnitud de sus componentes (t√≥picos) en la matriz SVD. Importante si est√° fuertemente conectada a los t√≥picos latentes del texto. |

---

## üìà 4. An√°lisis y Conclusiones (Punto 4)

El an√°lisis se dividi√≥ en dos fases para obtener una conclusi√≥n integral:

### An√°lisis Cuantitativo (Rendimiento)
* **Medici√≥n de Tiempos (Tabla 1, Figuras 1-4):** Se midi√≥ el tiempo de ejecuci√≥n para cada carta.
* **Hallazgo Clave:** Se identificaron tres niveles de velocidad. **BERT** (0.455s prom.) es masivamente m√°s lento que los dem√°s. **TF-IDF** (0.003s prom.) y **LSA** (0.004s) son los m√°s r√°pidos. BERT fue **140 veces m√°s lento** que TF-IDF.
* **Escalabilidad:** El tiempo de BERT es variable y sensible a la longitud del texto, mientras que los m√©todos estad√≠sticos mostraron un rendimiento casi constante.

### An√°lisis Cualitativo (Calidad)
* **An√°lisis de Caracter√≠sticas (Tabla 2):** Se verific√≥ el √©xito de la normalizaci√≥n (LSA fue el √∫nico en min√∫sculas, RAKE/BERT preservaron formato). Tambi√©n se demostr√≥ que `Frecuencia` tiende a seleccionar oraciones "basura" (cortas, como fechas).
* **An√°lisis de Similitud (Tabla 3, Figura 5):** Un mapa de calor visualiz√≥ el solapamiento (% de oraciones en com√∫n).
    * **TF-IDF y TextRank** mostraron una alta similitud (66.7%), ya que TextRank us√≥ TF-IDF como base.
    * **BERT** demostr√≥ ser una "isla" con baja similitud (ej. 14.6% con TF-IDF), probando que su l√≥gica de selecci√≥n (sem√°ntica) es fundamentalmente √∫nica.

### Veredicto Final (Tabla 4, Figuras 6-7)
No existe un "mejor" algoritmo; la elecci√≥n depende de la prioridad:

* **üèÜ Mejor Calidad Sem√°ntica:** **BERT**. Es el √∫nico que "entendi√≥" la narrativa (la aparici√≥n de la criatura en la Carta 4), pero a un costo de rendimiento extremo.
* **‚ö° Mejor Velocidad y Eficiencia:** **TF-IDF**. Ideal para procesamiento masivo donde la velocidad es cr√≠tica.
* **‚öñÔ∏è Mejor "Todo-Terreno" (Balance):** **RAKE**. La evaluaci√≥n multidimensional (Figura 6 y 7) lo clasific√≥ en primer lugar (21/25), mostrando un perfil equilibrado de buena velocidad, alta coherencia y excelente preservaci√≥n del formato.

---

## üöÄ C√≥mo Ejecutar

Este proyecto es un Jupyter Notebook (`.ipynb`) y requiere un entorno compatible.

### Requisitos
* Python 3.x
* Jupyter (Lab o Notebook)
* Las bibliotecas listadas en `requirements.txt`
* El modelo de lenguaje `en_core_web_sm` de `spaCy`.

### Pasos de Instalaci√≥n

1.  **Clonar el repositorio:**
    ```bash
    git clone [URL-DE-TU-REPOSITORIO]
    cd [NOMBRE-DEL-REPOSITORIO]
    ```

2.  **Instalar dependencias:**
    (Se recomienda crear un entorno virtual: `python -m venv venv` y `source venv/bin/activate`)
    ```bash
    pip install -r requirements.txt
    ```

3.  **Descargar los modelos y datos necesarios:**
    ```bash
    # Descargar modelo de spaCy
    python -m spacy download en_core_web_sm
    
    # Descargar paquetes de NLTK
    python -m nltk.downloader punkt
    python -m nltk.downloader stopwords
    python -m nltk.downloader wordnet
    ```

4.  **Iniciar Jupyter Lab:**
    ```bash
    jupyter lab
    ```

5.  Abrir el archivo `Practica3_EscamillaLazcanoSaul_5BV1.ipynb` y ejecutar las celdas.

---

## üìÑ Contenido para `requirements.txt`
(Crea un archivo `requirements.txt` y pega esto)
